{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import data\n",
    "import uncertainty_estimation as ue\n",
    "from main_bayesian import getModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA settings\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate uncertainties\n",
    "Load the model from checkpoint and test on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "_, testset, inputs, num_classes = data.getDataset('POCUS')\n",
    "\n",
    "# Load model\n",
    "ckpt = 'PATH_TO_CHECKPOINT'\n",
    "layer_type = cfg.layer_type\n",
    "activation_type = cfg.activation_type\n",
    "\n",
    "net = getModel('POCUS', inputs, num_classes, priors=None, layer_type=layer_type, activation_type=activation_type)\n",
    "net.load_state_dict(torch.load(weight_path)[\"model_state_dict\"])\n",
    "net.train() # should this be train or eval?\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_uncertainties(model):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection \n",
    "Look at the data with PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 3 components\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(testset.data.numpy().reshape(-1, 28*28))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(xs=[i[0] for i in pca_result], ys=[i[1] for i in pca_result], zs=[i[2] for i in pca_result], c=[i[5] for i in uncertainties])\n",
    "plt.title('PCA with 3 components')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE with 3 components (use PCA to reduce the dimensionality of the data first), color by label\n",
    "pca = PCA(n_components=30)\n",
    "pca_result = pca.fit_transform(testset.data.numpy().reshape(-1, 28*28))\n",
    "tsne = TSNE(n_components=3)\n",
    "tsne_result = tsne.fit_transform(pca_result)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(xs=[i[0] for i in tsne_result], ys=[i[1] for i in tsne_result], zs=[i[2] for i in tsne_result], c=[i[5] for i in uncertainties])\n",
    "plt.title('t-SNE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many correct and wrong prediction there were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many right and worng predictions there are for each class\n",
    "right = [0 for i in range(num_classes)]\n",
    "wrong = [0 for i in range(num_classes)]\n",
    "for i in uncertainties:\n",
    "    if i[4]:\n",
    "        right[int(i[5])] += 1\n",
    "    else:\n",
    "        wrong[int(i[5])] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Class', i, ' - ', 'Right:', right[i], ' , ', 'Wrong:', wrong[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check range of uncertainties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Epistemic Uncertainty (Normalized):', min([i[0] for i in uncertainties]), max([i[0] for i in uncertainties]))\n",
    "print('Aleatoric Uncertainty (Normalized):', min([i[1] for i in uncertainties]), max([i[1] for i in uncertainties]))\n",
    "print('Epistemic Uncertainty (Softmax):', min([i[2] for i in uncertainties]), max([i[2] for i in uncertainties]))\n",
    "print('Aleatoric Uncertainty (Softmax):', min([i[3] for i in uncertainties]), max([i[3] for i in uncertainties]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized epistemic uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_uncertainties(u_type, normalized, uncertainties):\n",
    "    \n",
    "    # get the correct index at which the uncertainty is stored\n",
    "    if u_type == 'epistemic':\n",
    "        if normalized:\n",
    "            u = 0\n",
    "        else:\n",
    "            u = 2\n",
    "    elif u_type == 'aleatoric':\n",
    "        if normalized:\n",
    "            u = 1\n",
    "        else:\n",
    "            u = 3\n",
    "    \n",
    "    # split the testset into 5 groups based on epistemic uncertainty (normalized)\n",
    "    testset0, testset1, testset2, testset3, testset4 = [], [], [], [], []\n",
    "    labels0, labels1, labels2, labels3, labels4 = [], [], [], [], []\n",
    "\n",
    "    for i, elem in enumerate(uncertainties):\n",
    "        if elem[u] < t1:\n",
    "            testset0.append(testset.data.numpy().reshape(-1, 28*28)[i])\n",
    "            labels0.append(elem[5])\n",
    "        elif elem[u] < t2:\n",
    "            testset1.append(testset.data.numpy().reshape(-1, 28*28)[i])\n",
    "            labels1.append(elem[5])\n",
    "        elif elem[u] < t3:\n",
    "            testset2.append(testset.data.numpy().reshape(-1, 28*28)[i])\n",
    "            labels2.append(elem[5])\n",
    "        elif elem[u] < t4:\n",
    "            testset3.append(testset.data.numpy().reshape(-1, 28*28)[i])\n",
    "            labels3.append(elem[5])\n",
    "        else:\n",
    "            testset4.append(testset.data.numpy().reshape(-1, 28*28)[i])\n",
    "            labels4.append(elem[5])\n",
    "\n",
    "    # create thresholds \n",
    "    t0 = min([i[0] for i in uncertainties])\n",
    "    t5 = max([i[0] for i in uncertainties])\n",
    "    steps = (t5-t0) / 5\n",
    "\n",
    "    t1 = t0 + steps\n",
    "    t2 = t1 + steps\n",
    "    t3 = t2 + steps\n",
    "    t4 = t3 + steps\n",
    "\n",
    "    testsets = [testset0, testset1, testset2, testset3, testset4]\n",
    "    thresholds = [t0, t1, t2, t3, t4, t5]\n",
    "    labelssets = [labels0, labels1, labels2, labels3, labels4]\n",
    "    vals = [\"small\", \"small-medium\", \"medium\", \"medium-large\", \"large\"]\n",
    "\n",
    "    return testsets, thresholds, labelssets, vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE with 3 components (use PCA to reduce the dimensionality of the data first), color by label\n",
    "def plot_tsne(uncertainties, u_type='epistemic', normalized=True):\n",
    "\n",
    "    testsets, thresholds, labelssets, vals = sort_uncertainties(u_type, normalized, uncertanties)\n",
    "\n",
    "    for i in range(len(testsets)):\n",
    "        set_i = testsets[i]\n",
    "        labels_i = labelssets[i]\n",
    "        if len(labels_i) < 30:\n",
    "            n_components = len(labels_i)\n",
    "        else:\n",
    "            n_components = 30\n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca_result = pca.fit_transform(set_i)\n",
    "        tsne = TSNE(n_components=3)\n",
    "        tsne_result = tsne.fit_transform(pca_result)\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(xs=[i[0] for i in tsne_result], ys=[i[1] for i in tsne_result], zs=[i[2] for i in tsne_result], c=labels_i, cmap='tab10')\n",
    "        plt.title('t-SNE for ' + vals[i] + ' epistemic uncertainty (normalized) (between ' + str(thresholds[i]) + ' and ' + str(thresholds[i+1]) + ')')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(uncertainties, u_type='epistemic', normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(uncertainties, u_type='epistemic', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(uncertainties, u_type='aleatoric', normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tsne(uncertainties, u_type='aleatoric', normalized=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
